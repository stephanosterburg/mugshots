{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py:603: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PanelGroupBy' from 'pandas.core.groupby' (/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36mpandas\u001b[0;34m(tclass, *targs, **tkwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;31m# pandas>=0.23.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m                 \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPanelGroupBy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataFrameGroupBy' from 'pandas.core.groupby.groupby' (/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-07f1e9d019bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"progress-bar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36mpandas\u001b[0;34m(tclass, *targs, **tkwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m                 \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPanelGroupBy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m                 \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPanelGroupBy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PanelGroupBy' from 'pandas.core.groupby' (/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "# import h5py\n",
    "import shutil\n",
    "import skimage\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# don't print matching warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset and unpack it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = 'https://s3.amazonaws.com/nist-srd/SD18/sd18.zip'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file('sd18.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'sd18/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 10\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2434/2434 [00:12<00:00, 199.15it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "filenames = glob(PATH + 'single/f1_p1/*/*.png')\n",
    "for filename in tqdm(filenames):\n",
    "    indx = filename.split('/')[-1].split('_')[0]\n",
    "    # remove leading zeros from index\n",
    "    indx = re.sub(r'(?<!\\d)0+', '', indx)\n",
    "    side = filename.split('/')[-1].split('_')[2].split('.')[0].lower()\n",
    "    new_file = 'data/mugshot_{}.{}.png'.format(side, indx)\n",
    "    shutil.copyfile(filename, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1217/1217 [03:51<00:00,  5.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert Grayscale to RGB \n",
    "# Resize to (256, 256)\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def as_gray(image_filter, image, *args, **kwargs):\n",
    "    gray_image = rgb2gray(image)\n",
    "    return image_filter(gray_image, *args, **kwargs)\n",
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def sobel_each(image):\n",
    "    return filters.sobel(image)\n",
    "\n",
    "@adapt_rgb(hsv_value)\n",
    "def sobel_hsv(image):\n",
    "    return filters.sobel(image)\n",
    "\n",
    "@adapt_rgb(as_gray)\n",
    "def sobel_gray(image):\n",
    "    return filters.sobel(image)\n",
    "\n",
    "# Convert Grayscale to RGB \n",
    "# Resize to (256, 256)\n",
    "filenames = glob('data/*.png')\n",
    "for filename in tqdm(filenames):\n",
    "    im = skimage.io.imread(filename)\n",
    "    im = skimage.color.gray2rgb(im)\n",
    "    im = skimage.transform.resize(im, (256, 256), anti_aliasing=True)\n",
    "    \n",
    "    if '_f' in filename:\n",
    "        im = skimage.exposure.equalize_adapthist(im, clip_limit=0.01)\n",
    "        im = skimage.exposure.adjust_log(im)\n",
    "        im = skimage.exposure.rescale_intensity(1 - sobel_each(im))\n",
    "        \n",
    "    im = skimage.util.img_as_ubyte(im)\n",
    "    skimage.io.imsave(filename, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:23<00:00,  5.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Flip L to R\n",
    "filenames = glob('data/mugshot_l.*.png')\n",
    "for filename in tqdm(filenames):\n",
    "    im = skimage.io.imread(filename)\n",
    "    im = np.fliplr(im)\n",
    "    skimage.io.imsave(filename, im)\n",
    "    # rename file\n",
    "    new_filename = filename.replace('_l', '_r')\n",
    "    os.rename(filename, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1217 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ea68e88f7337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmin_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimgs_comb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimgs_comb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_comb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "# Combine F and R image\n",
    "filenames = sorted(glob('data/mugshot_f.*.png'))\n",
    "k = 0\n",
    "for filename in tqdm(filenames):\n",
    "    images = [filename, filename.replace('_f', '_r')]\n",
    "    images = [Image.open(image) for image in images]\n",
    "    \n",
    "    min_shape = sorted([(np.sum(image.size), image.size) for image in images])[0][1]\n",
    "    imgs_comb = np.hstack((np.asarray(image.resize(min_shape)) for image in images))\n",
    "\n",
    "    imgs_comb = Image.fromarray(imgs_comb)\n",
    "    imgs_comb.save('data/mugshot_comp.{}.png'.format(k))\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('data/train'):\n",
    "    os.mkdir('data/train')\n",
    "    \n",
    "if not os.path.isdir('data/test'):\n",
    "    os.mkdir('data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "filenames = glob('data/mugshot_comp.*.png')\n",
    "\n",
    "for filename in filenames[:int(len(filenames)*0.8)]:\n",
    "    shutil.move(filename, 'data/train')\n",
    "    \n",
    "for filename in filenames[int(len(filenames)*0.8):]:\n",
    "    shutil.move(filename, 'data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up behind me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all png images\n",
    "files = glob('data/*.png')\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "\n",
    "# Remove downloaded data\n",
    "shutil.rmtree(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-to-Image paper describes that it randomly jitter each image\n",
    "1. resize image up\n",
    "2. randomly crop back to org size\n",
    "3. randomly flip horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.image.decode_png(image)\n",
    "    \n",
    "    width = tf.shape(image)[1] // 2\n",
    "    frnt_img = image[:, :width, :]\n",
    "    side_img = image[:, width:, :]\n",
    "    \n",
    "    frnt_img = tf.dtypes.cast(frnt_img, tf.float32)\n",
    "    side_img = tf.dtypes.cast(side_img, tf.float32)\n",
    "    \n",
    "    return frnt_img, side_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(frnt_img, side_img, h, w):\n",
    "    frnt_img = tf.image.resize(frnt_img, [h, w], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    side_img = tf.image.resize(side_img, [h, w], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    return frnt_img, side_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(frnt_img, side_img):\n",
    "    # stack both image on top to get the same cropped area\n",
    "    stck_img = tf.stack([frnt_img, side_img], axis=0)\n",
    "    crop_img = tf.image.random_crop(stck_img, size=[2, 256, 256, 3])\n",
    "    \n",
    "    return crop_img[0], crop_img[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(frnt_img, side_img):\n",
    "#     frnt_img = tf.image.per_image_standardization(frnt_img)\n",
    "#     side_img = tf.image.per_image_standardization(side_img)\n",
    "    frnt_img = (frnt_img / 127.5) - 1\n",
    "    side_img = (side_img / 127.5) - 1\n",
    "    \n",
    "    return frnt_img, side_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def random_jitter(frnt_image, side_image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    frnt_image, side_image = resize_img(frnt_image, side_image, 286, 286)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    frnt_image, side_image = random_crop(frnt_image, side_image)\n",
    "\n",
    "    # randomly mirroring only front image\n",
    "    frnt_image = tf.image.random_flip_left_right(frnt_image)\n",
    "\n",
    "    return frnt_image, side_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(filename):\n",
    "    frnt, side = load(filename)\n",
    "    frnt, side = random_jitter(frnt, side)\n",
    "    frnt, side = norm_img(frnt, side)\n",
    "    \n",
    "    return frnt, side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(filename):\n",
    "    frnt, side = load(filename)\n",
    "    frnt, side = resize_img(frnt, side, 256, 256)\n",
    "    frnt, side = norm_img(frnt, side)\n",
    "    \n",
    "    return frnt, side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = tf.data.Dataset.list_files('data/train/*.png')\n",
    "trainset = trainset.shuffle(BUFFER_SIZE)\n",
    "trainset = trainset.map(load_train)\n",
    "trainset = trainset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = tf.data.Dataset.list_files('data/test/*.png')\n",
    "testset = testset.map(load_test)\n",
    "testset = testset.batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(input_shape):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Encoder network\n",
    "    x = tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv0')(x)\n",
    "    conv0 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv1')(conv0)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv1 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv2')(conv1)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv2 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv3')(conv2)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv3 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv4')(conv3)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv4 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv5')(conv4)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv5 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv6')(conv5)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv6 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # tf.keras.layers.Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='enc_conv7')(conv6)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    conv7 = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Fully-connected layers to allow parts to move around.\n",
    "    # If you are running out of memory, you can comment some of them out.\n",
    "\n",
    "    # Flatten -> Dense -> LeakyReLU -> Dense -> LeakyReLU -> Dense -> LeakyReLU -> Dense -> LeakyReLU -> Dense -> LeakyReLU -> Reshape\n",
    "    x = tf.keras.layers.Flatten()(conv7)\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense1')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense2')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense3')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense4')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, input_shape=(1, 1, 512), name='dense5')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Reshape((1, 1, 512))(x)\n",
    "\n",
    "    # Decoder network\n",
    "    # tf.keras.layers.Conv2DTrans -> BatchNorm -> Dropout -> ReLU\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv7')(conv7)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> Dropout -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat6')([conv6, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv6')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> Dropout -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat5')([conv5, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv5')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat4')([conv4, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv4')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat3')([conv3, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(512, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat2')([conv2, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> BatchNorm -> ReLU\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat1')([conv1, x])\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                               kernel_initializer=initializer, \n",
    "                               use_bias=False, name='dec_conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Concat -> tf.keras.layers.Conv2DTrans -> TanH\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat0')([conv0, x])\n",
    "    outputs = tf.keras.layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same',\n",
    "                                              kernel_initializer=initializer,\n",
    "                                              use_bias=False, activation='tanh', \n",
    "                                              name='dec_conv0')(x)\n",
    "\n",
    "    # Return model. \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name='Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator((256, 256, 3))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "The discriminator takes the input shape of the image file and in our case it's (256, 256, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(source_shape, target_shape):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    input_image = tf.keras.Input(source_shape, name='input_image')\n",
    "    target_image = tf.keras.Input(target_shape, name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1, name='concat')([input_image, target_image])\n",
    "\n",
    "    # Conv -> LeakyReLU\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='valid', use_bias=False,\n",
    "                               kernel_initializer=initializer, name='disc_conv0')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (4, 4), strides=(2, 2), padding='valid', use_bias=False,\n",
    "                               kernel_initializer=initializer, name='disc_conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (4, 4), strides=(2, 2), padding='valid', use_bias=False,\n",
    "                               kernel_initializer=initializer, name='disc_conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Conv -> BatchNorm -> LeakyReLU\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    x = tf.keras.layers.Conv2D(512, (4, 4), strides=(1, 1), name='disc_conv3', \n",
    "                               kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Conv -> Sigmoid\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=1, data_format='channels_last')(x)\n",
    "    outputs = tf.keras.layers.Conv2D(1, (4, 4), strides=(1, 1), name='validity', use_bias=False,\n",
    "                                     kernel_initializer=initializer, activation='sigmoid')(x)\n",
    "\n",
    "    # Return model\n",
    "    return tf.keras.Model(inputs=[input_image, target_image], outputs=outputs, name='Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator((256, 256, 3), (256, 256, 3))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frnt, side = load('data/train/mugshot_comp.111.png')\n",
    "\n",
    "gen_out = generator(frnt[tf.newaxis,...], training=False)\n",
    "plt.imshow(gen_out[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_out = discriminator([frnt[tf.newaxis,...], gen_out], training=False)\n",
    "plt.imshow(dis_out[0,...,-1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1_weight and gan_weight are taken from the Image-to-Iamge paper.\n",
    "# The numbers scale the two components of the loss function in the GAN.\n",
    "l1_weight = 100.0\n",
    "gan_weight = 1.0\n",
    "\n",
    "# Epsilon\n",
    "epsilon = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output): \n",
    "    total_loss = tf.reduce_mean(-(tf.math.log(real_output + epsilon) + tf.math.log(1 - fake_output + epsilon)))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, target_images, generated_images):\n",
    "    gen_loss_GAN = tf.reduce_mean(-tf.math.log(fake_output + epsilon))\n",
    "    gen_loss_L1 = tf.reduce_mean(tf.math.abs(target_images - generated_images))\n",
    "    total_loss = gen_loss_GAN * gan_weight + gen_loss_L1 * l1_weight\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.99, epsilon=epsilon)\n",
    "dis_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5, beta_2=0.99, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'data/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=gen_optimizer,\n",
    "                                 discriminator_optimizer=dis_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    # the training=True is intentional here since\n",
    "    # we want the batch statistics while running the model\n",
    "    # on the test dataset. If we use training=False, we will get\n",
    "    # the accumulated statistics learned from the training dataset\n",
    "    # (which we don't want)\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        dis_real_output = discriminator([input_image, target], training=True)\n",
    "        dis_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_loss = generator_loss(dis_generated_output, gen_output, target)\n",
    "        dis_loss = discriminator_loss(dis_real_output, dis_generated_output)\n",
    "\n",
    "    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    dis_gradients = dis_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(dis_gradients, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for input_image, target in dataset:\n",
    "            train_step(input_image, target)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        for inp, tar in testset.take(1):\n",
    "            generate_images(generator, inp, tar)\n",
    "\n",
    "        # saving (checkpoint) the model every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Epoch {} took {} sec\\n'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(trainset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate image from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the trained model on the entire test dataset\n",
    "for inp, tar in testset.take(5):\n",
    "    generate_images(generator, inp, tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
